{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0184b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 A\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(265)\n",
    "\n",
    "def pca(X, num_components):\n",
    "    # Standardize the dataset\n",
    "    X_standardized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    # Compute covariance matrix\n",
    "    covariance_matrix = np.cov(X_standardized.T)\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    # Sort eigenvectors by eigenvalues in descending order\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, idx]\n",
    "    # Select the first num_components eigenvectors\n",
    "    projection_matrix = sorted_eigenvectors[:, :num_components]\n",
    "    # Project the data onto the selected eigenvectors\n",
    "    X_pca = np.dot(X_standardized, projection_matrix)\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5de6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.12904143  0.03071774]\n",
      " [ 0.57145644  0.49852797]\n",
      " [ 0.64306291 -0.37870717]\n",
      " ...\n",
      " [ 3.12521466 -0.69424899]\n",
      " [-1.4631027   0.5342782 ]\n",
      " [ 1.05196736 -0.54871574]]\n"
     ]
    }
   ],
   "source": [
    "# 2 B\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "file_path = 'moral_machine_data.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "results_columns = [\n",
    "    'man_no_of_passengers_died', 'man_no_of_pedestrians_on_lane_ahead_died', 'man_no_of_pedestrians_on_other_lane_died',\n",
    "    'man_no_of_passengers_saved', 'man_no_of_pedestrians_on_lane_ahead_saved', 'man_no_of_pedestrians_on_other_lane_saved',\n",
    "    'woman_no_of_passengers_died', 'woman_no_of_pedestrians_on_lane_ahead_died', 'woman_no_of_pedestrians_on_other_lane_died',\n",
    "    'woman_no_of_passengers_saved', 'woman_no_of_pedestrians_on_lane_ahead_saved', 'woman_no_of_pedestrians_on_other_lane_saved',\n",
    "    'boy_no_of_passengers_died', 'boy_no_of_pedestrians_on_lane_ahead_died', 'boy_no_of_pedestrians_on_other_lane_died',\n",
    "    'boy_no_of_passengers_saved', 'boy_no_of_pedestrians_on_lane_ahead_saved', 'boy_no_of_pedestrians_on_other_lane_saved',\n",
    "    'girl_no_of_passengers_died', 'girl_no_of_pedestrians_on_lane_ahead_died', 'girl_no_of_pedestrians_on_other_lane_died',\n",
    "    'girl_no_of_passengers_saved', 'girl_no_of_pedestrians_on_lane_ahead_saved', 'girl_no_of_pedestrians_on_other_lane_saved',\n",
    "    'elderly_man_no_of_passengers_died', 'elderly_man_no_of_pedestrians_on_lane_ahead_died', 'elderly_man_no_of_pedestrians_on_other_lane_died',\n",
    "    'elderly_man_no_of_passengers_saved', 'elderly_man_no_of_pedestrians_on_lane_ahead_saved', 'elderly_man_no_of_pedestrians_on_other_lane_saved',\n",
    "    'elderly_woman_no_of_passengers_died', 'elderly_woman_no_of_pedestrians_on_lane_ahead_died', 'elderly_woman_no_of_pedestrians_on_other_lane_died',\n",
    "    'elderly_woman_no_of_passengers_saved', 'elderly_woman_no_of_pedestrians_on_lane_ahead_saved', 'elderly_woman_no_of_pedestrians_on_other_lane_saved',\n",
    "    'large_man_no_of_passengers_died', 'large_man_no_of_pedestrians_on_lane_ahead_died', 'large_man_no_of_pedestrians_on_other_lane_died',\n",
    "    'large_man_no_of_passengers_saved', 'large_man_no_of_pedestrians_on_lane_ahead_saved', 'large_man_no_of_pedestrians_on_other_lane_saved',\n",
    "    'large_woman_no_of_passengers_died', 'large_woman_no_of_pedestrians_on_lane_ahead_died', 'large_woman_no_of_pedestrians_on_other_lane_died',\n",
    "    'large_woman_no_of_passengers_saved', 'large_woman_no_of_pedestrians_on_lane_ahead_saved', 'large_woman_no_of_pedestrians_on_other_lane_saved',\n",
    "    'male_executive_no_of_passengers_died', 'male_executive_no_of_pedestrians_on_lane_ahead_died', 'male_executive_no_of_pedestrians_on_other_lane_died',\n",
    "    'male_executive_no_of_passengers_saved', 'male_executive_no_of_pedestrians_on_lane_ahead_saved', 'male_executive_no_of_pedestrians_on_other_lane_saved',\n",
    "     'female_executive_no_of_passengers_died', 'female_executive_no_of_pedestrians_on_lane_ahead_died', 'female_executive_no_of_pedestrians_on_other_lane_died',\n",
    "    'female_executive_no_of_passengers_saved', 'female_executive_no_of_pedestrians_on_lane_ahead_saved', 'female_executive_no_of_pedestrians_on_other_lane_saved',\n",
    "    'male_doctor_no_of_passengers_died', 'male_doctor_no_of_pedestrians_on_lane_ahead_died', 'male_doctor_no_of_pedestrians_on_other_lane_died',\n",
    "    'male_doctor_no_of_passengers_saved', 'male_doctor_no_of_pedestrians_on_lane_ahead_saved', 'male_doctor_no_of_pedestrians_on_other_lane_saved',\n",
    "    'female_doctor_no_of_passengers_died', 'female_doctor_no_of_pedestrians_on_lane_ahead_died', 'female_doctor_no_of_pedestrians_on_other_lane_died',\n",
    "    'female_doctor_no_of_passengers_saved', 'female_doctor_no_of_pedestrians_on_lane_ahead_saved', 'female_doctor_no_of_pedestrians_on_other_lane_saved',\n",
    "    'male_athlete_no_of_passengers_died', 'male_athlete_no_of_pedestrians_on_lane_ahead_died', 'male_athlete_no_of_pedestrians_on_other_lane_died',\n",
    "    'male_athlete_no_of_passengers_saved', 'male_athlete_no_of_pedestrians_on_lane_ahead_saved', 'male_athlete_no_of_pedestrians_on_other_lane_saved',\n",
    "    'female_athlete_no_of_passengers_died', 'female_athlete_no_of_pedestrians_on_lane_ahead_died', 'female_athlete_no_of_pedestrians_on_other_lane_died',\n",
    "    'female_athlete_no_of_passengers_saved', 'female_athlete_no_of_pedestrians_on_lane_ahead_saved', 'female_athlete_no_of_pedestrians_on_other_lane_saved',\n",
    "    'pregnant_woman_no_of_passengers_died', 'pregnant_woman_no_of_pedestrians_on_lane_ahead_died', 'pregnant_woman_no_of_pedestrians_on_other_lane_died',\n",
    "    'pregnant_woman_no_of_passengers_saved', 'pregnant_woman_no_of_pedestrians_on_lane_ahead_saved', 'pregnant_woman_no_of_pedestrians_on_other_lane_saved',\n",
    "    'homeless_person_no_of_passengers_died', 'homeless_person_no_of_pedestrians_on_lane_ahead_died', 'homeless_person_no_of_pedestrians_on_other_lane_died',\n",
    "    'homeless_person_no_of_passengers_saved', 'homeless_person_no_of_pedestrians_on_lane_ahead_saved', 'homeless_person_no_of_pedestrians_on_other_lane_saved',\n",
    "    'criminal_no_of_passengers_died', 'criminal_no_of_pedestrians_on_lane_ahead_died', 'criminal_no_of_pedestrians_on_other_lane_died',\n",
    "    'criminal_no_of_passengers_saved', 'criminal_no_of_pedestrians_on_lane_ahead_saved', 'criminal_no_of_pedestrians_on_other_lane_saved',\n",
    "    'baby_no_of_passengers_died', 'baby_no_of_pedestrians_on_lane_ahead_died', 'baby_no_of_pedestrians_on_other_lane_died',\n",
    "    'baby_no_of_passengers_saved', 'baby_no_of_pedestrians_on_lane_ahead_saved', 'baby_no_of_pedestrians_on_other_lane_saved',\n",
    "    'dog_no_of_passengers_died', 'dog_no_of_pedestrians_on_lane_ahead_died', 'dog_no_of_pedestrians_on_other_lane_died',\n",
    "    'dog_no_of_passengers_saved', 'dog_no_of_pedestrians_on_lane_ahead_saved', 'dog_no_of_pedestrians_on_other_lane_saved',\n",
    "    'cat_no_of_passengers_died', 'cat_no_of_pedestrians_on_lane_ahead_died', 'cat_no_of_pedestrians_on_other_lane_died',\n",
    "    'cat_no_of_passengers_saved', 'cat_no_of_pedestrians_on_lane_ahead_saved', 'cat_no_of_pedestrians_on_other_lane_saved'\n",
    "]\n",
    "\n",
    "X = df[results_columns].values\n",
    "\n",
    "# Perform PCA with 2 components\n",
    "X_pca = pca(X, num_components=2)\n",
    "\n",
    "#print(\"Projected data shape:\", X_pca.shape)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d85517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['pca_dim_1', 'pca_dim_2'])\n",
    "df = pd.concat([df.reset_index(drop=True), pca_df], axis=1)\n",
    "df['no_of_siblings'] = df['no_of_sisters'] + df['no_of_brothers']\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 18, 30, 40, 50, 60, np.inf], labels=['0-18', '19-30', '31-40', '41-50', '51-60', '60+'])\n",
    "\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Function to plot PCA with labels and optional text labels\n",
    "def plot_pca_with_labels(df, label_column, text_column=None, title=''):\n",
    "    unique_labels = df[label_column].unique()\n",
    "    pal = sns.color_palette(\"Paired\", n_colors=len(unique_labels))\n",
    "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "    df['mapped_label'] = df[label_column].map(label_mapping)\n",
    "    \n",
    "    p1 = sns.scatterplot(x=\"pca_dim_1\", y=\"pca_dim_2\", hue='mapped_label', palette=pal, data=df, s=250, alpha=0.7, legend=False)\n",
    "    \n",
    "    if text_column:\n",
    "        for line in range(0, df.shape[0]):\n",
    "            p1.text(df.pca_dim_1[line], df.pca_dim_2[line], df[text_column][line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "\n",
    "    plt.suptitle(title, fontsize=36)\n",
    "    plt.xlabel('PCA - Dimension 1', fontsize=24)\n",
    "    plt.ylabel('PCA - Dimension 2', fontsize=24)\n",
    "    \n",
    "    # Plotting the convex hulls\n",
    "    for i in unique_labels:\n",
    "        mapped_label = label_mapping[i]\n",
    "        points = df[df['mapped_label'] == mapped_label][['pca_dim_1', 'pca_dim_2']].values\n",
    "        if points.shape[0] > 2:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(points)\n",
    "            x_hull = np.append(points[hull.vertices,0], points[hull.vertices,0][0])\n",
    "            y_hull = np.append(points[hull.vertices,1], points[hull.vertices,1][0])\n",
    "            \n",
    "            # Interpolate\n",
    "            dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "            dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "            spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "            interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "            interp_x, interp_y = interpolate.splev(interp_d, spline)\n",
    "            \n",
    "            # Plot shape\n",
    "            plt.fill(interp_x, interp_y, '--', c=pal[mapped_label], alpha=0.2)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for 'age' (assuming 'age_group' has been created as described earlier)\n",
    "plot_pca_with_labels(df, 'age_group', title='PCA by Age Group')\n",
    "\n",
    "# For 'gender'\n",
    "plot_pca_with_labels(df, 'gender ', title='PCA by Gender')\n",
    "\n",
    "# For 'grown_up_in_US'\n",
    "plot_pca_with_labels(df, 'grown_up_in_US ', title='PCA by Grown Up in US')\n",
    "\n",
    "# For 'country_of_origin' (assuming country names are provided)\n",
    "plot_pca_with_labels(df, 'country_of_origin', text_column='country_of_origin', title='PCA by Country of Origin')\n",
    "\n",
    "# For 'no_of_siblings' (assuming it's already in df)\n",
    "plot_pca_with_labels(df, 'no_of_siblings', title='PCA by Number of Siblings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d510c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'X' is the dataset matrix you want to transform\n",
    "embedding = SpectralEmbedding(n_components=2, random_state=0)\n",
    "X_transformed = embedding.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame for the transformed data\n",
    "spectral_df = pd.DataFrame(X_transformed, columns=['spectral_dim_1', 'spectral_dim_2'])\n",
    "\n",
    "# Add the spectral dimensions to your original DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), spectral_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf6a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_spectral_with_labels(df, label_column, title):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    \n",
    "    # Update 'palette' as needed based on the number of unique labels\n",
    "    unique_labels = df[label_column].unique()\n",
    "    palette = sns.color_palette(\"Spectral\", n_colors=len(unique_labels))\n",
    "    \n",
    "    sns.scatterplot(data=df, x='spectral_dim_1', y='spectral_dim_2', hue=label_column, palette=palette, s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel('Spectral Dimension 1', fontsize=18)\n",
    "    plt.ylabel('Spectral Dimension 2', fontsize=18)\n",
    "    plt.legend(title=label_column, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to adjust these columns based on how you prepared your DataFrame\n",
    "plot_spectral_with_labels(df, 'age_group', 'Spectral Embedding by Age Group')\n",
    "plot_spectral_with_labels(df, 'gender ', 'Spectral Embedding by Gender')\n",
    "plot_spectral_with_labels(df, 'grown_up_in_US ', 'Spectral Embedding by Grown Up in US')\n",
    "plot_spectral_with_labels(df, 'country_of_origin', 'Spectral Embedding by Country of Origin')\n",
    "\n",
    "# Assuming 'no_of_siblings' is already in your DataFrame\n",
    "plot_spectral_with_labels(df, 'no_of_siblings', 'Spectral Embedding by Number of Siblings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009aab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Assuming 'X' is your dataset matrix with samples as rows and features as columns\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame for the T-SNE transformed data\n",
    "tsne_df = pd.DataFrame(X_tsne, columns=['tsne_dim_1', 'tsne_dim_2'])\n",
    "\n",
    "# Merge this DataFrame back into your original DataFrame if necessary\n",
    "df = pd.concat([df.reset_index(drop=True), tsne_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe4725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_tsne_with_labels(df, label_column, title):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    unique_labels = df[label_column].unique()\n",
    "    palette = sns.color_palette(\"Spectral\", n_colors=len(unique_labels))\n",
    "\n",
    "    sns.scatterplot(data=df, x='tsne_dim_1', y='tsne_dim_2', hue=label_column, palette=palette, s=100, alpha=0.7)\n",
    "\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel('T-SNE Dimension 1', fontsize=18)\n",
    "    plt.ylabel('T-SNE Dimension 2', fontsize=18)\n",
    "    plt.legend(title=label_column, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you've prepared 'age_group', 'gender', 'grown_up_in_US', 'country_of_origin', and 'no_of_siblings' in df\n",
    "\n",
    "# Age\n",
    "plot_tsne_with_labels(df, 'age_group', 'T-SNE by Age Group')\n",
    "\n",
    "# Gender\n",
    "plot_tsne_with_labels(df, 'gender ', 'T-SNE by Gender')\n",
    "\n",
    "# Grown Up in US\n",
    "plot_tsne_with_labels(df, 'grown_up_in_US ', 'T-SNE by Grown Up in US')\n",
    "\n",
    "# Country of Origin\n",
    "plot_tsne_with_labels(df, 'country_of_origin ', 'T-SNE by Country of Origin')\n",
    "\n",
    "# Number of Siblings\n",
    "plot_tsne_with_labels(df, 'no_of_siblings', 'T-SNE by Number of Siblings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcac8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "# New dimension reduction columns from PCA, Spectral Embedding, and t-SNE\n",
    "dim_reduction_cols = ['age',\n",
    "                   'no_of_siblings', \n",
    "                   'pca_dim_1', 'pca_dim_2', \n",
    "                   'spectral_dim_1', 'spectral_dim_2', \n",
    "                   'tsne_dim_1', 'tsne_dim_2']\n",
    "\n",
    "# Selecting only the necessary columns for correlation analysis\n",
    "df_selected = df[dim_reduction_cols]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df_selected.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
